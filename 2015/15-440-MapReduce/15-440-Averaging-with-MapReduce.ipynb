{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Simple Averaging: not so Simple with MapReduce\n",
      "\n",
      "This is the simplest example I can think of which can not easily use the combiner optimization within MapReduce.  If you come up with a simpler example, find mistakes/typos, or have questions email [wolf@cs.cmu.edu](mailto:wolf@cs.cmu.edu).\n",
      "\n",
      "## Dataset\n",
      "\n",
      "Let's assume we have requests for a website and we want to average them."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataset = [\n",
      "           ('g.co', 2),\n",
      "           ('g.co', 3),\n",
      "           ('g.co', 4)\n",
      "          ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First off, averaging is simple (even in your head):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(2 + 3 + 4) / 3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "3.0"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Combining (Partial Averaging) Fails"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The problem with averaging these using combiners is that division is neither associative nor commutative.  Although it should be deterministic!\n",
      "\n",
      "Imagine that the first two records are located on one worker, and the last record is located on another worker.\n",
      "\n",
      "Averaging using a combiner on the first worker would yield:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(2 + 3) / 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "2.5"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And, averaging using a combiner on the second worker would yield:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(4) / 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "4.0"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Then these two results from the combiners would be sent via RPC to the reducer worker.\n",
      "\n",
      "The result of averaging at the reducer would be:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(2.5 + 4.0) / 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "3.25"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Advanced MapReduce: Customizing the Combiner Function\n",
      "\n",
      "The way to fix this is *not* to compute partial averages with combining at map workers, but to keep a partial sum and count of records processed.  MapReduce lets users specify custom `combine` functions which are different from the `reduce` function.\n",
      "\n",
      "Let's take a look at an implementation that would work on this dataset.  First, the `map` which is really just the identity function in this case (practical MR implementations also let you skip the `map` phase if you want):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def map(key, value):\n",
      "    return (key, value) # pretend return is actually `EmitIntermediate`"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now let's take a look at `combine`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def combine(key, valueIterator):\n",
      "    n = 0\n",
      "    total = 0\n",
      "    \n",
      "    for _, v in valueIterator:\n",
      "        n += 1\n",
      "        total += v\n",
      "    return (key, (n, total)) # see, no division!"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`combine` simply keeps a count of the records its seen, computes a partial sum over them, and returns this partial result.\n",
      "\n",
      "`reduce` looks a bit more complicated, but it is actually very simple just summing all the partial results:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def reduce(key, valueIterator):\n",
      "    n = 0\n",
      "    total = 0\n",
      "    for _, partialResult in valueIterator:\n",
      "        partialCount, partialTotal = partialResult\n",
      "        n += partialCount\n",
      "        total += partialTotal\n",
      "    return (key, total / n) # pretend that return is actually `Emit`"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If you're convinced, no need to read on.  Otherwise...\n",
      "\n",
      "## Verifying the Implementation\n",
      "\n",
      "First, we `map`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mappedDataset = [map(k,v) for k,v in dataset]\n",
      "print(mappedDataset)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('g.co', 2), ('g.co', 3), ('g.co', 4)]\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As expected, each entry is now converted into a partial result, although it is basically the identity function.\n",
      "\n",
      "Next we run `combine` for the first worker (the one with the first two records):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "combinedWorker1 = combine('g.co', [mappedDataset[0], mappedDataset[1]])\n",
      "combinedWorker2 = combine('g.co', [mappedDataset[2]])\n",
      "print(combinedWorker1)\n",
      "print(combinedWorker2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('g.co', (2, 5))\n",
        "('g.co', (1, 4))\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So, two partial results move on to the reducer representing 3 total records, and the `reduce` function produces:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "finalResult = reduce('g.co', [combinedWorker1, combinedWorker2])\n",
      "print(finalResult)\n",
      "assert finalResult[1] == 3.0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('g.co', 3.0)\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Which represents the correct answer!\n",
      "\n",
      "Hopefully you understand why it is important to verify that a `reduce` function can directly be used in the `combine` optimization.\n",
      "\n",
      "This also demonstrates that there is a tension between implementing optimizations and affecting algorithm correctness.  To achieve a useful distributed system performance optimization, you may have to rethink an algorithm."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}